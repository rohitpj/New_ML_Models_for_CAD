{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72874,
     "status": "ok",
     "timestamp": 1714563830660,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "3WwnIJmhWIBz",
    "outputId": "92ca3b75-d6d0-4eb4-eca8-df3654b59305"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WI93GO7v50Pm"
   },
   "outputs": [],
   "source": [
    "def evaluate_predictions(predictions, test_labels, test_times, test_cells):\n",
    "    total_time = 0.0\n",
    "    total_cells = 0\n",
    "\n",
    "    # Convert string representations to actual lists\n",
    "    test_times_lists = test_times.apply(lambda x: ast.literal_eval(x))\n",
    "    test_cells_lists = test_cells.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    valid_predictions = 0\n",
    "\n",
    "    for i, pred in enumerate(predictions):\n",
    "        label = int(pred)\n",
    "        if label < len(test_times_lists.iloc[i]) and label < len(test_cells_lists.iloc[i]):\n",
    "            total_time += test_times_lists.iloc[i][label]\n",
    "            total_cells += test_cells_lists.iloc[i][label]\n",
    "            valid_predictions += 1\n",
    "\n",
    "    avg_time = total_time / valid_predictions if valid_predictions > 0 else 0\n",
    "    avg_cells = total_cells / valid_predictions if valid_predictions > 0 else 0\n",
    "    print(avg_time, avg_cells)\n",
    "    return avg_time, avg_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XkVzbNNB0Fy"
   },
   "outputs": [],
   "source": [
    "def run_lr(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  #print(\"Logistic Regression\")\n",
    "  lr = LogisticRegression(max_iter=5000, multi_class='multinomial')\n",
    "  lr.fit(X_train, y_train)\n",
    "  lr_y_pred = lr.predict(X_test)\n",
    "\n",
    "  lr_accuracy_score=accuracy_score(y_test, lr_y_pred)\n",
    "  print(f'LR accuracy: {lr_accuracy_score*100:.2f}%')\n",
    "  #print(classification_report(y_test, lr_y_pred))\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(lr_y_pred, y_test, test_times, test_cells)\n",
    "  return lr,lr_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGrm5zCpC0V6"
   },
   "outputs": [],
   "source": [
    "def run_gbm(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  #print(\"Gradient Boosting Machine\")\n",
    "  gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "  gbm.fit(X_train, y_train)\n",
    "  gbm_y_pred = gbm.predict(X_test)\n",
    "\n",
    "  #print(classification_report(y_test, gbm_y_pred))\n",
    "  gbm_accuracy_score=accuracy_score(y_test, gbm_y_pred)\n",
    "  print(f'GBM accuracy: {gbm_accuracy_score*100:.2f}%')\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(gbm_y_pred, y_test, test_times, test_cells)\n",
    "  return gbm,gbm_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl0CYGmpC-kq"
   },
   "outputs": [],
   "source": [
    "def run_svm(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  svm = SVC(kernel='linear', C=1, probability=True, random_state=42)\n",
    "  svm.fit(X_train, y_train)\n",
    "  svm_y_pred = svm.predict(X_test)\n",
    "\n",
    "  svm_accuracy_score=accuracy_score(y_test, svm_y_pred)\n",
    "  print(f'SVM accuracy: {svm_accuracy_score*100:.2f}%')\n",
    "  #print(classification_report(y_test, svm_y_pred))\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(svm_y_pred, y_test, test_times, test_cells)\n",
    "  return svm,svm_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TG4uN4QDX8Q"
   },
   "outputs": [],
   "source": [
    "def run_knn(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='ball_tree')\n",
    "  knn.fit(X_train, y_train)\n",
    "  #print(\"K-Nearest-Neighbour\")\n",
    "  knn_y_pred = knn.predict(X_test)\n",
    "\n",
    "  knn_accuracy_score = accuracy_score(y_test, knn_y_pred)\n",
    "  print(f'KNN accuracy: {knn_accuracy_score*100:.2f}%')\n",
    "  #print(classification_report(y_test, knn_y_pred))\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(knn_y_pred, y_test, test_times, test_cells)\n",
    "  return knn,knn_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUOokPWvo-Ys"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_dt(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  dt = DecisionTreeClassifier(criterion='gini', max_depth=17)\n",
    "  dt.fit(X_train, y_train)\n",
    "  dt_y_pred = dt.predict(X_test)\n",
    "\n",
    "  #print(classification_report(y_test, dt_y_pred))\n",
    "  dt_accuracy_score = accuracy_score(y_test, dt_y_pred)\n",
    "  print(f'DT accuracy: {dt_accuracy_score*100:.2f}%')\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(dt_y_pred, y_test, test_times, test_cells)\n",
    "  return dt,dt_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OibPxzvtpAgC"
   },
   "outputs": [],
   "source": [
    "def run_rf(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "  rf.fit(X_train, y_train)\n",
    "  rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "  #print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "  rf_accuracy_score = accuracy_score(y_test, rf_y_pred)\n",
    "  print(f'RF accuracy: {rf_accuracy_score*100:.2f}%')\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(rf_y_pred, y_test, test_times, test_cells)\n",
    "  return rf,rf_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvvsWdcU-Ziu"
   },
   "outputs": [],
   "source": [
    "def run_xgb(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "  xgb.fit(X_train, y_train)\n",
    "  xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "  # Display the classification report\n",
    "  #print(classification_report(y_test, xgb_y_pred))\n",
    "\n",
    "  xgb_accuracy_score = accuracy_score(y_test, xgb_y_pred)\n",
    "  print(f'XGBoost accuracy: {xgb_accuracy_score*100:.2f}%')\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(xgb_y_pred, y_test, test_times, test_cells)\n",
    "  return xgb,xgb_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1IjAeDsFmwD"
   },
   "outputs": [],
   "source": [
    "def run_ensemble(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "  rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "  dt = DecisionTreeClassifier(criterion='gini', max_depth=17)\n",
    "  knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='ball_tree')\n",
    "  svm = SVC(kernel='linear', C=1, probability=True, random_state=42)\n",
    "  gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "  lr = LogisticRegression(max_iter=5000, multi_class='multinomial')\n",
    "\n",
    "  ensemble = VotingClassifier(estimators=[ ('knn', knn),('gbm',gbm),('dt',dt)], voting='soft')\n",
    "  ensemble.fit(X_train, y_train)\n",
    "\n",
    "  ensemble_y_pred = ensemble.predict(X_test)\n",
    "  ensemble_accuracy_score=accuracy_score(y_test, ensemble_y_pred)\n",
    "  print(f'Ensemble accuracy: {ensemble_accuracy_score*100:.2f}%')\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(ensemble_y_pred, y_test, test_times, test_cells)\n",
    "  return ensemble_y_pred#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ltzUinYK0SN"
   },
   "outputs": [],
   "source": [
    "def run_ffn(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "  scaler = StandardScaler()\n",
    "  FFN_X_train = scaler.fit_transform(X_train)\n",
    "  FFN_X_test = scaler.transform(X_test)\n",
    "\n",
    "  # Convert labels to one-hot encoding\n",
    "  FFN_y_train = tf.keras.utils.to_categorical(y_train, num_classes=6)\n",
    "  FFN_y_test = tf.keras.utils.to_categorical(y_test, num_classes=6)\n",
    "\n",
    "  model = Sequential([\n",
    "      Dense(128, activation='relu', input_shape=(FFN_X_train.shape[1],)),\n",
    "      Dense(128, activation='relu'),\n",
    "      Dense(64, activation='relu'),\n",
    "      Dense(64, activation='relu'),\n",
    "      Dense(32, activation='relu'),\n",
    "      Dense(32, activation='relu'),\n",
    "      Dense(6, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  history = model.fit(FFN_X_train, FFN_y_train, epochs=50, batch_size=32, validation_split=0.2,verbose=0)\n",
    "\n",
    "\n",
    "  test_loss, test_acc = model.evaluate(FFN_X_test, FFN_y_test,verbose=1)\n",
    "\n",
    "  print(f'FFN accuracy: {test_acc*100:.2f}%')\n",
    "  predictions = model.predict(FFN_X_test)\n",
    "  predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "  true_classes = np.argmax(FFN_y_test, axis=1)\n",
    "\n",
    "  #report = classification_report(true_classes, predicted_classes, target_names=['0', '1', '2','3','4','5'])  # Adjust target_names based on your dataset\n",
    "  #print(report)\n",
    "  if evaluation==True:\n",
    "    total_time, total_cells = evaluate_predictions(predicted_classes, y_test, test_times, test_cells)\n",
    "  return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APWvj4d1Yzcd"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_brown(X_train, y_train,X_test,y_test,evaluation=False):\n",
    "\n",
    "  def brown_select_variable_order(variable_info):\n",
    "      variable_stats = [\n",
    "          (\n",
    "              info['max_degree'],  # Lowest degree first\n",
    "              -info['prop'],       # Highest proportion of terms (use -prop for descending sort)\n",
    "              -info['prop_mon'],   # Highest total degree term (use -prop_mon for descending sort)\n",
    "              var                 # Variable name for tie-breaking by name\n",
    "          )\n",
    "          for var, info in variable_info.items()\n",
    "      ]\n",
    "\n",
    "      variable_stats.sort()\n",
    "      variable_ordering = [var for _, _, _, var in variable_stats]\n",
    "\n",
    "      ordering_str = ''.join(var.replace('x', '') for var in variable_ordering)\n",
    "      ordering_map = {\n",
    "          '123': 0, '132': 1, '213': 2,\n",
    "          '231': 3, '312': 4, '321': 5\n",
    "      }\n",
    "\n",
    "      return ordering_map.get(ordering_str, None)\n",
    "\n",
    "\n",
    "  def brown_calculate_ordering(row):\n",
    "\n",
    "      variable_info = {\n",
    "          'x1': {'max_degree': row['max_x1'], 'prop': row['prop_x1'], 'prop_mon': row['prop_mon_x1']},\n",
    "          'x2': {'max_degree': row['max_x2'], 'prop': row['prop_x2'], 'prop_mon': row['prop_mon_x2']},\n",
    "          'x3': {'max_degree': row['max_x3'], 'prop': row['prop_x3'], 'prop_mon': row['prop_mon_x3']},\n",
    "      }\n",
    "      ordering = brown_select_variable_order(variable_info)\n",
    "      return ordering\n",
    "\n",
    "  X_test['ordering_index'] = X_test.apply(brown_calculate_ordering, axis=1)\n",
    "  matches = (X_test['ordering_index'] == X_test['label']).sum()\n",
    "  total = len(X_test)\n",
    "  brown_accuracy = matches / total * 100\n",
    "  print(f\"Brown Accuracy: {brown_accuracy}%\")\n",
    "  total_time, total_cells = evaluate_predictions(X_test['ordering_index'], X_test['label'], X_test['time'], X_test['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQiBgAhFAwm6"
   },
   "outputs": [],
   "source": [
    "def list_parser(cell_string):\n",
    "    try:\n",
    "        stripped_string = cell_string.strip('[]')\n",
    "        parsed_list = [float(item.strip()) for item in stripped_string.split(',') if item.strip()]\n",
    "        return parsed_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing cell_string: {cell_string} due to {e}\")\n",
    "        return []\n",
    "\n",
    "def remove_duplicate_lowest(df_copy, column_name):\n",
    "    df = df_copy.copy()\n",
    "    df[column_name] = df[column_name].apply(list_parser)\n",
    "\n",
    "    def has_duplicate_lowest(cells):\n",
    "        if not cells:\n",
    "            return False\n",
    "        lowest_value = min(cells)\n",
    "        return cells.count(lowest_value) > 1\n",
    "\n",
    "    filtered_df = df[~df[column_name].apply(has_duplicate_lowest)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_duplicate_lowest(df_copy, column_name):\n",
    "    df = df_copy.copy()\n",
    "    df[column_name] = df[column_name].apply(list_parser)\n",
    "\n",
    "    def has_duplicate_lowest(cells):\n",
    "        if not cells:\n",
    "            return False\n",
    "        lowest_value = min(cells)\n",
    "        return cells.count(lowest_value) > 1\n",
    "\n",
    "    filtered_df = df[df[column_name].apply(has_duplicate_lowest)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def add_timeout_column(df):\n",
    "    df['cells'] = df['cells'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['time'] = df['time'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    def adjust_entries(row):\n",
    "        if 30 in row['time'] and 1000 in row['cells']:\n",
    "            return 1\n",
    "        return 0\n",
    "    df['timeout'] = df.apply(adjust_entries, axis=1)\n",
    "    return df\n",
    "\n",
    "def remove_timeout_entries(df_copy):\n",
    "    df=df_copy.copy()\n",
    "    df_filtered = df[df['timeout'] == 0]\n",
    "    return df_filtered\n",
    "\n",
    "def adjust_time_and_cells(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if isinstance(row['time'], list) and 30.0 in row['time']:\n",
    "            max_time_not_30 = max([time for time in row['time'] if time != 30.0], default=0)\n",
    "            new_time = max_time_not_30 + 30\n",
    "            row['time'] = [new_time if time == 30.0 else time for time in row['time']]\n",
    "            df.at[index, 'time'] = row['time']\n",
    "\n",
    "        if isinstance(row['cells'], list) and 1000 in row['cells']:\n",
    "            max_cells_not_1000 = max([cell for cell in row['cells'] if cell != 1000], default=0)\n",
    "            new_cells = max_cells_not_1000 + 1000\n",
    "            row['cells'] = [new_cells if cell == 1000 else cell for cell in row['cells']]\n",
    "            df.at[index, 'cells'] = row['cells']\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_duplicate_names(df_copy):\n",
    "  df=df_copy.copy().sample(frac=1)\n",
    "  df['poly_name'] = df['input_file'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "  df_unique = df.drop_duplicates(subset=['poly_name'], keep='first')\n",
    "  df_unique=df_unique.drop('poly_name',axis=1)\n",
    "  return df_unique\n",
    "\n",
    "def get_times_and_cells(df):\n",
    "  return df[[\"time\",\"cells\"]]\n",
    "\n",
    "def rank_times(times_list):\n",
    "    sorted_times = sorted((time, index) for index, time in enumerate(times_list))\n",
    "    ranks = [0] * len(times_list)\n",
    "\n",
    "    for rank, (time, index) in enumerate(sorted_times):\n",
    "        ranks[index] = rank\n",
    "\n",
    "    return ranks\n",
    "\n",
    "def generate_final_df():\n",
    "  file_path = '/Data/final_merged_data.csv'\n",
    "  merged_df = pd.read_csv(file_path)\n",
    "\n",
    "  adjusted_df = add_timeout_column(merged_df)\n",
    "  adjusted_df=adjust_time_and_cells(merged_df)\n",
    "\n",
    "  output_file_path = '/Data/extra_added_timeout_data_.csv'\n",
    "  adjusted_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fNrn1OmMGjJ"
   },
   "outputs": [],
   "source": [
    "def apply_reductions(df_og,shuffle,remove_dupe_lowest,remove_timeouts,remove_dupe_names,frac_to_keep):\n",
    "  df=copy.deepcopy(df_og)\n",
    "  if shuffle==True:\n",
    "    df=df.sample(frac=1)\n",
    "  if remove_dupe_lowest==True:\n",
    "    remove_duplicate_lowest(df,'time')\n",
    "  if remove_timeouts==True:\n",
    "    df=remove_timeout_entries(df)\n",
    "  if remove_dupe_names==True:\n",
    "    df=remove_duplicate_names(df)\n",
    "  return df.sample(frac=frac_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZkXU9wm2bX-"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_train_test_data(original_df,extra_features=False):\n",
    "    if extra_features==False:\n",
    "      df_copy = original_df.copy()\n",
    "      df_copy = df_copy.drop(columns=['Unnamed: 0'])\n",
    "      train_df, test_df = train_test_split(df_copy, test_size=0.2, random_state=42)\n",
    "      y_train = train_df['label']\n",
    "      y_test = test_df['label']\n",
    "      feature_columns_to_drop = ['cells', 'label', 'file_id_x', 'file_id_y', 'input_file', 'label_file', 'time', 'timeout']\n",
    "      X_train = train_df.drop(feature_columns_to_drop, axis=1)\n",
    "      X_test = test_df.drop(feature_columns_to_drop, axis=1)\n",
    "      return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "      df_copy = original_df.copy()\n",
    "      df_copy = df_copy.drop(columns=['file_id_x'])\n",
    "      train_df, test_df = train_test_split(df_copy, test_size=0.2, random_state=42)\n",
    "      y_train = train_df['label_y']\n",
    "      y_test = test_df['label_y']\n",
    "      feature_columns_to_drop = ['label_y']\n",
    "      X_train = train_df.drop(feature_columns_to_drop, axis=1)\n",
    "      X_test = test_df.drop(feature_columns_to_drop, axis=1)\n",
    "      return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_3Z1eoaVtkN"
   },
   "outputs": [],
   "source": [
    "def run_all(X_train, y_train, og_X_test, og_y_test,lr,gbm,svm,knn,dt,xgb,ensemble,ffn,brown):\n",
    "    if lr:\n",
    "        lr,lr_y_pred=run_lr(X_train, y_train,og_X_test,og_y_test)\n",
    "    if gbm:\n",
    "        gbm,gbm_y_pred=run_gbm(X_train, y_train,og_X_test,og_y_test)\n",
    "    if svm:\n",
    "        svm,svm_y_pred=run_svm(X_train, y_train,og_X_test,og_y_test)\n",
    "    if knn:\n",
    "        knn,knn_y_pred=run_knn(X_train, y_train,og_X_test,og_y_test)\n",
    "    if dt:\n",
    "        dt,dt_y_pred=run_dt(X_train, y_train,og_X_test,og_y_test)\n",
    "    if xgb:\n",
    "        xgb,xgb_y_pred=run_xgb(X_train, y_train,og_X_test,og_y_test)\n",
    "    #if ensemble:\n",
    "        #ensemble,ensemble_y_pred=run_ensemble(X_train, y_train,X_test,y_test)\n",
    "    if ffn:\n",
    "        ffn_y_pred=run_ffn(X_train, y_train,og_X_test,og_y_test)\n",
    "    #if brown:\n",
    "        #run_brown(X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSNN61HNutLD"
   },
   "outputs": [],
   "source": [
    "file_path = '/Data/extra_added_timeout_data_.csv'\n",
    "\n",
    "og_df = pd.read_csv(file_path)\n",
    "augmented_df= og_df.sort_values(by='file_id_x')\n",
    "split_ratio = 0.8\n",
    "\n",
    "split_index = int(len(augmented_df) * split_ratio)\n",
    "\n",
    "og_train_df = og_df[:split_index]\n",
    "og_test_df = og_df[split_index:]\n",
    "\n",
    "og_train_df = og_train_df.sample(frac=1)\n",
    "og_test_df = og_test_df.sample(frac=1)\n",
    "\n",
    "augmented_train_df = augmented_df[:split_index]\n",
    "augmented_test_df = augmented_df[split_index:]\n",
    "\n",
    "augmented_train_df = augmented_train_df.sample(frac=1)\n",
    "augmented_test_df = augmented_test_df.sample(frac=1)\n",
    "\n",
    "balanced_train_df=remove_duplicate_names(augmented_train_df)\n",
    "balanced_test_df=remove_duplicate_names(augmented_test_df)\n",
    "\n",
    "balanced_train_df = balanced_train_df.sample(frac=1)\n",
    "balanced_test_df = balanced_test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eMPT59J9VGC"
   },
   "outputs": [],
   "source": [
    "duplicate_times=get_duplicate_lowest(og_df,'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1714563832339,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "gh2_PA959uGp",
    "outputId": "1544e56a-d782-4de9-929d-6852b09db522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 20)\n"
     ]
    }
   ],
   "source": [
    "print(duplicate_times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1714563832340,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "OqVucIqkogDd",
    "outputId": "b4a971c3-d7d2-4f41-8338-571ef0915153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5516, 20) (33095, 20)\n"
     ]
    }
   ],
   "source": [
    "print(balanced_train_df.shape,augmented_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IBCUmqFAERp"
   },
   "outputs": [],
   "source": [
    "unbalanced_file_path = '/Data/metitarski_original_processed.csv'\n",
    "\n",
    "unbalanced_df = pd.read_csv(unbalanced_file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoqUs4RV6yUO"
   },
   "outputs": [],
   "source": [
    "unbalanced_df['numeric_id'] = unbalanced_df['input_file'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "unbalanced_df= unbalanced_df.sort_values(by='numeric_id')\n",
    "split_ratio = 0.8\n",
    "\n",
    "split_index = int(len(unbalanced_df) * split_ratio)\n",
    "\n",
    "unbalanced_train_df = unbalanced_df[:split_index]\n",
    "unbalanced_test_df = unbalanced_df[split_index:]\n",
    "\n",
    "unbalanced_train_df = unbalanced_train_df.sample(frac=1)\n",
    "unbalanced_test_df = unbalanced_test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1714563833572,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "8WijvHAd9RKu",
    "outputId": "7b8b7837-e678-4db2-a922-8df233182cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5516, 17) (5516, 20) (33095, 20) (33095, 20)\n"
     ]
    }
   ],
   "source": [
    "print(unbalanced_train_df.shape,balanced_train_df.shape,augmented_train_df.shape,og_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1714563833920,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "5aOQdWmuQbX3",
    "outputId": "e482eef6-4a54-44be-c304-1cc352197d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identical rows in training sets after re-merging: 6621\n",
      "Number of identical rows in training sets after removal: 6621\n"
     ]
    }
   ],
   "source": [
    "common_train = pd.merge(og_train_df, augmented_test_df, on='input_file', how='inner')\n",
    "print(f'Number of identical rows in training sets after re-merging: {len(common_train)}')\n",
    "\n",
    "og_no_pollution_train_df = og_train_df[~og_train_df['input_file'].isin(common_train['input_file'])]\n",
    "\n",
    "common_train = pd.merge(og_train_df, augmented_test_df, on='input_file', how='inner')\n",
    "print(f'Number of identical rows in training sets after removal: {len(common_train)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1714563834181,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "8Q79kf1cVPsp",
    "outputId": "4c986297-1b4c-407e-b943-28598f7ed4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identical rows in training sets after re-merging: 1104\n",
      "Number of identical rows in training sets after removal: 0\n"
     ]
    }
   ],
   "source": [
    "common_train = pd.merge(og_train_df, balanced_test_df, on='input_file', how='inner')\n",
    "print(f'Number of identical rows in training sets after re-merging: {len(common_train)}')\n",
    "\n",
    "og_train_df = og_train_df[~og_train_df['input_file'].isin(common_train['input_file'])]\n",
    "\n",
    "common_train = pd.merge(og_train_df, balanced_test_df, on='input_file', how='inner')\n",
    "print(f'Number of identical rows in training sets after removal: {len(common_train)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1714563857300,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "rYieLPLLQrvj",
    "outputId": "825eb315-12f4-4cea-b8ec-27275e5e1fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31991, 20) (33095, 20) (5516, 20)\n"
     ]
    }
   ],
   "source": [
    "print(og_train_df.shape,augmented_train_df.shape,balanced_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwjY5x9HEPUj"
   },
   "outputs": [],
   "source": [
    "feature_columns_to_drop = ['Unnamed: 0','cells', 'label', 'file_id_x', 'file_id_y', 'input_file', 'label_file', 'time', 'timeout']\n",
    "\n",
    "og_no_pollution_y_train = og_no_pollution_train_df['label']\n",
    "og_no_pollution_X_train = og_no_pollution_train_df.drop(feature_columns_to_drop, axis=1)\n",
    "og_no_pollution_y_test = og_no_pollution_train_df['label']\n",
    "og_no_pollution_X_test = og_no_pollution_train_df.drop(feature_columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imSo3fZOTdwJ"
   },
   "outputs": [],
   "source": [
    "feature_columns_to_drop = ['Unnamed: 0','cells', 'label', 'file_id_x', 'file_id_y', 'input_file', 'label_file', 'time', 'timeout']\n",
    "\n",
    "og_y_train = og_train_df['label']\n",
    "og_X_train = og_train_df.drop(feature_columns_to_drop, axis=1)\n",
    "og_y_test = og_test_df['label']\n",
    "og_X_test = og_test_df.drop(feature_columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPt2CmgL90nl"
   },
   "outputs": [],
   "source": [
    "augmented_y_train = augmented_train_df['label']\n",
    "augmented_X_train = augmented_train_df.drop(feature_columns_to_drop, axis=1)\n",
    "augmented_y_test = augmented_test_df['label']\n",
    "augmented_X_test = augmented_test_df.drop(feature_columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi3HqOjW-A9D"
   },
   "outputs": [],
   "source": [
    "balanced_y_train = balanced_train_df['label']\n",
    "balanced_X_train = balanced_train_df.drop(feature_columns_to_drop, axis=1)\n",
    "balanced_y_test = balanced_test_df['label']\n",
    "balanced_X_test = balanced_test_df.drop(feature_columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-skLr7V-Lu-"
   },
   "outputs": [],
   "source": [
    "less_feature_columns_to_drop = ['Unnamed: 0', 'label', 'file_id', 'input_file', 'label_file','numeric_id']\n",
    "\n",
    "unbalanced_y_train = unbalanced_train_df['label']\n",
    "unbalanced_X_train = unbalanced_train_df.drop(less_feature_columns_to_drop, axis=1)\n",
    "unbalanced_y_test = unbalanced_test_df['label']\n",
    "unbalanced_X_test = unbalanced_test_df.drop(less_feature_columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sERZ89uqGkJb"
   },
   "source": [
    "**Data Pollution Experiment**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1714564070921,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "M-btAKkXoVAI",
    "outputId": "78b0b5a2-34bd-4869-c539-48782fa67e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33095, 11) (5516, 11)\n"
     ]
    }
   ],
   "source": [
    "print(augmented_X_train.shape,balanced_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 444615,
     "status": "ok",
     "timestamp": 1714489495676,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "fET-qhMogegt",
    "outputId": "d505777d-dc26-42af-9104-90fa29061706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy: 27.70%\n",
      "DT accuracy: 35.68%\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.9494 - accuracy: 0.4264\n",
      "FFN accuracy: 42.64%\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "-----------------------------\n",
      "KNN accuracy: 24.95%\n",
      "DT accuracy: 35.24%\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.2796 - accuracy: 0.3270\n",
      "FFN accuracy: 32.70%\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "-----------------------------\n",
      "KNN accuracy: 15.45%\n",
      "DT accuracy: 24.29%\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3297 - accuracy: 0.3009\n",
      "FFN accuracy: 30.09%\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "-----------------------------\n",
      "KNN accuracy: 58.81%\n",
      "DT accuracy: 60.77%\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.8915 - accuracy: 0.6200\n",
      "FFN accuracy: 62.00%\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "-----------------------------\n",
      "KNN accuracy: 26.69%\n",
      "DT accuracy: 38.36%\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6974 - accuracy: 0.4177\n",
      "FFN accuracy: 41.77%\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "run_all(augmented_X_train, augmented_y_train,balanced_X_test,balanced_y_test,lr=False, gbm=False, svm=False, knn=True, dt=True, xgb=False, ensemble=False, ffn=True, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(balanced_X_train, balanced_y_train,balanced_X_test,balanced_y_test,lr=False, gbm=False, svm=False, knn=True, dt=True, xgb=False, ensemble=False, ffn=True, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(unbalanced_X_train, unbalanced_y_train,balanced_X_test,balanced_y_test,lr=False, gbm=False, svm=False, knn=True, dt=True, xgb=False, ensemble=False, ffn=True, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_X_train, og_y_train,balanced_X_test,balanced_y_test,lr=False, gbm=False, svm=False, knn=True, dt=True, xgb=False, ensemble=False, ffn=True, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_no_pollution_X_train, og_no_pollution_y_train,balanced_X_test,balanced_y_test,lr=False, gbm=False, svm=False, knn=True, dt=True, xgb=False, ensemble=False, ffn=True, brown=False)\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46570,
     "status": "ok",
     "timestamp": 1714476600816,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "Oqwgj8w0ANqd",
    "outputId": "b29852f4-52d8-402a-e272-aa3246367bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 41.12%\n",
      "KNN accuracy: 27.48%\n",
      "DT accuracy: 35.10%\n",
      "XGBoost accuracy: 46.92%\n",
      "-----------------------------\n",
      "LR accuracy: 42.57%\n",
      "KNN accuracy: 29.95%\n",
      "DT accuracy: 38.00%\n",
      "XGBoost accuracy: 44.16%\n",
      "-----------------------------\n",
      "LR accuracy: 23.71%\n",
      "KNN accuracy: 14.21%\n",
      "DT accuracy: 24.00%\n",
      "XGBoost accuracy: 37.13%\n",
      "-----------------------------\n",
      "LR accuracy: 45.61%\n",
      "KNN accuracy: 58.52%\n",
      "DT accuracy: 60.19%\n",
      "XGBoost accuracy: 60.84%\n",
      "-----------------------------\n",
      "LR accuracy: 40.97%\n",
      "KNN accuracy: 26.25%\n",
      "DT accuracy: 37.64%\n",
      "XGBoost accuracy: 46.05%\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "run_all(augmented_X_train, augmented_y_train,balanced_X_test,balanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(balanced_X_train, balanced_y_train,balanced_X_test,balanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(unbalanced_X_train, unbalanced_y_train,balanced_X_test,balanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_X_train, og_y_train,balanced_X_test,balanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_no_pollution_X_train, og_no_pollution_y_train,balanced_X_test,balanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65142,
     "status": "ok",
     "timestamp": 1714476870811,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "S4CaMwMuYPvA",
    "outputId": "1e1ca866-2655-47a7-cca4-d6efd2eafead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 43.12%\n",
      "KNN accuracy: 26.24%\n",
      "DT accuracy: 35.39%\n",
      "XGBoost accuracy: 48.05%\n",
      "-----------------------------\n",
      "LR accuracy: 44.16%\n",
      "KNN accuracy: 29.36%\n",
      "DT accuracy: 35.91%\n",
      "XGBoost accuracy: 44.55%\n",
      "-----------------------------\n",
      "LR accuracy: 23.94%\n",
      "KNN accuracy: 15.12%\n",
      "DT accuracy: 24.76%\n",
      "XGBoost accuracy: 37.18%\n",
      "-----------------------------\n",
      "LR accuracy: 47.34%\n",
      "KNN accuracy: 70.67%\n",
      "DT accuracy: 69.60%\n",
      "XGBoost accuracy: 68.24%\n",
      "-----------------------------\n",
      "LR accuracy: 42.49%\n",
      "KNN accuracy: 27.19%\n",
      "DT accuracy: 35.79%\n",
      "XGBoost accuracy: 47.20%\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "run_all(augmented_X_train, augmented_y_train,augmented_X_test,augmented_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(balanced_X_train, balanced_y_train,augmented_X_test,augmented_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(unbalanced_X_train, unbalanced_y_train,augmented_X_test,augmented_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_X_train, og_y_train,augmented_X_test,augmented_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_no_pollution_X_train, og_no_pollution_y_train,augmented_X_test,augmented_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45260,
     "status": "ok",
     "timestamp": 1714476916061,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "MMF3M7pzEhjr",
    "outputId": "bbc3eafd-2440-4875-9ea2-c601ebace6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 41.04%\n",
      "KNN accuracy: 22.77%\n",
      "DT accuracy: 32.49%\n",
      "XGBoost accuracy: 45.25%\n",
      "-----------------------------\n",
      "LR accuracy: 40.32%\n",
      "KNN accuracy: 28.93%\n",
      "DT accuracy: 27.05%\n",
      "XGBoost accuracy: 37.49%\n",
      "-----------------------------\n",
      "LR accuracy: 33.65%\n",
      "KNN accuracy: 22.70%\n",
      "DT accuracy: 41.04%\n",
      "XGBoost accuracy: 43.44%\n",
      "-----------------------------\n",
      "LR accuracy: 42.42%\n",
      "KNN accuracy: 68.02%\n",
      "DT accuracy: 68.09%\n",
      "XGBoost accuracy: 68.17%\n",
      "-----------------------------\n",
      "LR accuracy: 41.70%\n",
      "KNN accuracy: 26.47%\n",
      "DT accuracy: 24.15%\n",
      "XGBoost accuracy: 41.77%\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "run_all(augmented_X_train, augmented_y_train,unbalanced_X_test,unbalanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(balanced_X_train, balanced_y_train,unbalanced_X_test,unbalanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(unbalanced_X_train, unbalanced_y_train,unbalanced_X_test,unbalanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_X_train, og_y_train,unbalanced_X_test,unbalanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_no_pollution_X_train, og_no_pollution_y_train,unbalanced_X_test,unbalanced_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47801,
     "status": "ok",
     "timestamp": 1714476963852,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "HXAjBcYWF9XK",
    "outputId": "c4f1a9c6-13f9-478f-f0b3-e023e8897496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 43.17%\n",
      "KNN accuracy: 57.40%\n",
      "DT accuracy: 58.44%\n",
      "XGBoost accuracy: 60.58%\n",
      "-----------------------------\n",
      "LR accuracy: 40.62%\n",
      "KNN accuracy: 46.88%\n",
      "DT accuracy: 50.10%\n",
      "XGBoost accuracy: 53.73%\n",
      "-----------------------------\n",
      "LR accuracy: 20.05%\n",
      "KNN accuracy: 24.03%\n",
      "DT accuracy: 27.33%\n",
      "XGBoost accuracy: 35.82%\n",
      "-----------------------------\n",
      "LR accuracy: 42.40%\n",
      "KNN accuracy: 51.99%\n",
      "DT accuracy: 52.30%\n",
      "XGBoost accuracy: 55.02%\n",
      "-----------------------------\n",
      "LR accuracy: 42.47%\n",
      "KNN accuracy: 45.09%\n",
      "DT accuracy: 48.67%\n",
      "XGBoost accuracy: 51.45%\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "run_all(augmented_X_train, augmented_y_train,og_X_test,og_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(balanced_X_train, balanced_y_train,og_X_test,og_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(unbalanced_X_train, unbalanced_y_train,og_X_test,og_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_X_train, og_y_train,og_X_test,og_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")\n",
    "run_all(og_no_pollution_X_train, og_no_pollution_y_train,og_X_test,og_y_test,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=False, brown=False)\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QP2n1MDpGqJ9"
   },
   "source": [
    "**Feature Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1714569566143,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "3Q-YMT9NpNbW"
   },
   "outputs": [],
   "source": [
    "def run_all(train_df,test_df,lr,gbm,svm,knn,dt,xgb,ensemble,ffn,brown,extra_features=False):\n",
    "    print(train_df.shape,test_df.shape)\n",
    "    X_train, y_train, X_test, y_test = prepare_train_test_data(train_df,extra_features)\n",
    "    og_X_train, og_y_train, og_X_test, og_y_test = prepare_train_test_data(test_df,extra_features)\n",
    "    if lr:\n",
    "        lr,lr_y_pred=run_lr(X_train, y_train,og_X_test,og_y_test)\n",
    "    if gbm:\n",
    "        gbm,gbm_y_pred=run_gbm(X_train, y_train,og_X_test,og_y_test)\n",
    "    if svm:\n",
    "        svm,svm_y_pred=run_svm(X_train, y_train,og_X_test,og_y_test)\n",
    "    if knn:\n",
    "        knn,knn_y_pred=run_knn(X_train, y_train,X_test,y_test)\n",
    "    if dt:\n",
    "        dt,dt_y_pred=run_dt(X_train, y_train,og_X_test,og_y_test)\n",
    "    if xgb:\n",
    "        xgb,xgb_y_pred=run_xgb(X_train, y_train,og_X_test,og_y_test)\n",
    "    if ffn:\n",
    "        ffn_y_pred=run_ffn(X_train, y_train,og_X_test,og_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1714570778643,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "oY-vqFFZzb_N"
   },
   "outputs": [],
   "source": [
    "def gen_extra_features_df():\n",
    "  new_file_path = '/Data/extra_features_data'\n",
    "  extra_features_df = pd.read_csv(new_file_path)\n",
    "  final_df = pd.read_csv('/Data/extra_added_timeout_data_.csv')\n",
    "  selected_columns = ['label'] + list(extra_features_df.columns[2:])\n",
    "  filtered_df = extra_features_df[selected_columns]\n",
    "\n",
    "  joined_df = pd.merge(final_df, extra_features_df, left_on='input_file', right_on='name', how='inner')\n",
    "  joined_df=joined_df.drop(['Unnamed: 0', 'label_file', 'input_file','nr_polynomials', 'max_total_degree', 'max_x1', 'max_x2', 'max_x3', 'prop_x1', 'prop_x2', 'prop_x3', 'prop_mon_x1', 'prop_mon_x2', 'prop_mon_x3', 'label_x', 'file_id_y'],axis=1)\n",
    "  feature_columns_to_drop = ['cells', 'time', 'timeout','name']\n",
    "  joined_df = joined_df.drop(feature_columns_to_drop, axis=1)\n",
    "  return joined_df\n",
    "\n",
    "extra_features_df=gen_extra_features_df()\n",
    "\n",
    "split_index = int(len(extra_features_df) * split_ratio)\n",
    "\n",
    "og_train_df = extra_features_df[:split_index]\n",
    "og_test_df = extra_features_df[split_index:]\n",
    "feature_columns_to_drop = ['Unnamed: 0','cells', 'label', 'file_id_x', 'file_id_y', 'input_file', 'label_file', 'time', 'timeout']\n",
    "\n",
    "y_train = og_train_df['label_y']\n",
    "y_test = og_test_df['label_y']\n",
    "X_train = og_train_df.drop(['label_y'], axis=1)\n",
    "X_test = og_test_df.drop(['label_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242061,
     "status": "ok",
     "timestamp": 1714571022184,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "7IVUjL7y1S6v",
    "outputId": "69aeab02-4f1b-4611-e523-0d3d7f677937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41369, 44) (41369, 44)\n",
      "LR accuracy: 49.09%\n",
      "KNN accuracy: 56.56%\n",
      "DT accuracy: 58.45%\n",
      "XGBoost accuracy: 59.08%\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.5996\n",
      "FFN accuracy: 59.96%\n",
      "259/259 [==============================] - 0s 1ms/step\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "run_all(extra_features_df, extra_features_df,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=True, brown=False,extra_features=True)\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160858,
     "status": "ok",
     "timestamp": 1714495785871,
     "user": {
      "displayName": "Rohit John",
      "userId": "06224148796144481458"
     },
     "user_tz": -60
    },
    "id": "5BEtR3kQ375I",
    "outputId": "6ea23da4-c4fd-4753-d522-3b2a966fbab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41369, 20) (41369, 20)\n",
      "LR accuracy: 42.12%\n",
      "KNN accuracy: 54.12%\n",
      "DT accuracy: 54.44%\n",
      "XGBoost accuracy: 56.55%\n",
      "259/259 [==============================] - 1s 3ms/step - loss: 1.0258 - accuracy: 0.5760\n",
      "FFN accuracy: 57.60%\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Data/extra_added_timeout_data_.csv'\n",
    "\n",
    "og_df = pd.read_csv(file_path)\n",
    "\n",
    "run_all(og_df, og_df,lr=True, gbm=False, svm=False, knn=True, dt=True, xgb=True, ensemble=False, ffn=True, brown=False,extra_features=False)\n",
    "print(\"-----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
